---
layout:     post
title:      基于骨架的动作识别PoseC3D
subtitle:   
date:       2022-01-24
author:     Yuan Zhao
header-img: img/bg-default.jpg
catalog: true
tags:
    - 动作识别
    - 深度学习
    - 计算机视觉
---
# 背景
基于骨架的动作识别

# GCN的局限性
* 鲁棒性：GCN的识别能力很受骨骼点坐标点平移的影响
* 互操作性：之前研究表明，不同模态（RGB、光流、骨架）是互补的，不同模态的结合能提升识别的性能。GCN很难与其他模态融合
* 可扩展性：GCN将每个人的单一骨骼点视为一个节点，当人数增加时，GCN的复杂度线性增加

本文提出的PoseC3D相比GCN（部分）克服了以上局限性
# 整体框架
![在这里插入图片描述](https://img-blog.csdnimg.cn/2d213343ad874184bc6859c8db7f14e2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAbm90enk=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)
1. 姿态估计：人体骨骼点坐标
2. 热图生成
3. PoseC3D：分类

# 热图生成
根据骨骼点坐标，使用高斯核生成，每帧生成K✖️H✖️W的热图，然后将T帧的堆叠得到整个序列的3D 热图，维度为K✖️T✖️H✖️W。其中K为骨骼点的数量，T为帧数
 <img src="https://img-blog.csdnimg.cn/be723375eafc44b5b899b6e4d3a06568.png" width="60%" alt=""/>

实际使用中，使用了两个技巧分别去除了空间和时间维度的冗余：subject centered cropping和uniform sampling。
* subject centered cropping：取包含所有帧中subject边界框的最小外接边界框，进行crop，再resize成模型所需的H✖️W
* uniform sampling：将序列n等分成n个segment，再从每个segment中随机采样一帧，得到n帧热图

# 模型
采用了SlowFast的魔改版

 <img src="https://img-blog.csdnimg.cn/47355d98ab234a07b12ee11dde1cffff.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAbm90enk=,size_20,color_FFFFFF,t_70,g_se,x_16" width="60%" alt=""/>

# 结果
97.1CV 94.1CS @NTU RGB-D

参考
[1] Duan, H., Zhao, Y., Chen, K., Shao, D., Lin, D., & Dai, B. (2021). Revisiting Skeleton-based Action Recognition. arXiv preprint arXiv:2104.13586.
