---
layout:     post
title:      基于骨架的动作识别DDNet
subtitle:   
date:       2022-01-23
author:     Yuan Zhao
header-img: img/bg-default.jpg
catalog: true
tags:
    - 动作识别
    - 深度学习
    - 计算机视觉
---
# 背景
基于骨架的动作识别/手势识别方法

# 整体框架
1. 特征提取，包括**位置、视角不变**的局部特征，即单帧特征关节集合距离JCD和两种尺度的全局特征，即帧间运动特征slow&fast motion

2. 特征嵌入

3. 特征融合

4. 分类

# 特征提取

 <img src="https://img-blog.csdnimg.cn/10e20845fae74adca992d0322e34528d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAbm90enk=,size_20,color_FFFFFF,t_70,g_se,x_16" width="40%" alt=""/>
 
在行为/手势识别任务中，有的类别是和**全局运动无关**的，如上图中的捏；而有的类别是和**全局运动相关**的，如上图中的划V。DDNet设计了JCD和Motion分别提取这两种情况的特征，即题目中的**Double Feature**

## JCD
### 计算方式
骨骼点间的欧式距离，即JCD

 <img src="https://img-blog.csdnimg.cn/49e037b819714ebc90c39c25fc6df538.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAbm90enk=,size_20,color_FFFFFF,t_70,g_se,x_16" width="60%" alt=""/>
 
### 解释
文中示意图所示，具有位置和视角不变性，即不管人体/手部骨架在空间中的什么位置，从什么视角观测，骨骼点间的欧式距离是不变的；相反，骨骼点的笛卡尔坐标随着骨架位置和观察视角的变化而变化。JCD的位置和视角不变性减小了类内方差，使模型学习更轻松
 <img src="https://img-blog.csdnimg.cn/8f970076d2f34113977e13a2ca51c73a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAbm90enk=,size_20,color_FFFFFF,t_70,g_se,x_16" width="40%" alt=""/>

 ## Slow & Fast Motion
 ### 计算方式
 slow motion和fast motion分别是骨骼点坐标的帧间和隔帧间差值

 <img src="https://img-blog.csdnimg.cn/dea54d275fb34c34b3e1abe67b35fa9a.png" width="40%" alt=""/>
 
### 解释
 <img src="https://img-blog.csdnimg.cn/e37ce2a85e5d423799e2df0a53de1024.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAbm90enk=,size_20,color_FFFFFF,t_70,g_se,x_16" width="40%" alt=""/>
 
动态手势/行为中，不同样本中主体（subject）运动的速率可能不同，为了使不同速率的运动都能得到合适的表示，DDNet使用了Slow和Fast两种尺度的帧间运动特征

# 网络结构
 <img src="https://img-blog.csdnimg.cn/ff1414452fc441248ccb8e161716e4e0.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAbm90enk=,size_20,color_FFFFFF,t_70,g_se,x_16" width="60%" alt=""/>
 
DDNet使用的算子很基础，主要是一维卷积和MLP。从结构上，DDNet分三路分别对输入特征做embedding；拼接三路embedding，融合；使用全局池化得到全局embedding；使用常规的MLP做分类

# 实现
TODO
# 结果
91.9% @SHREC
77.2% @JHMDB

参考
[1] Yang, F., Wu, Y., Sakti, S., & Nakamura, S. (2019). Make skeleton-based action recognition model smaller, faster and better. In Proceedings of the ACM multimedia asia (pp. 1-6).
